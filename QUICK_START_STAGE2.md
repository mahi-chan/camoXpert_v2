# ğŸš€ Quick Start: Resume Stage 2 Training on Kaggle

## âœ… Your Current Status
- **Stage 1**: âœ“ Complete (Epoch 30, IoU: 0.5480)
- **Stage 2**: Ready to start (Epochs 31-120)
- **Problem**: Previous OOM error at epoch 31
- **Solution**: Memory-optimized resume now available

## ğŸ¯ Three Ways to Resume

### Option 1: Helper Script (Easiest) â­

```bash
bash resume_stage2.sh
```

This script will:
- âœ“ Verify your checkpoint
- âœ“ Check GPU memory
- âœ“ Configure optimal settings
- âœ“ Start Stage 2 training

### Option 2: Direct Command (Recommended)

```bash
python train_ultimate.py train \
  --dataset-path /kaggle/input/cod10k \
  --resume-from checkpoints/best_model.pth \
  --skip-stage1 \
  --stage2-batch-size 1 \
  --gradient-checkpointing \
  --progressive-unfreeze \
  --accumulation-steps 4
```

### Option 3: Copy-Paste Kaggle Cell

```python
# Run this in a Kaggle notebook cell
!python train_ultimate.py train \
  --dataset-path /kaggle/input/cod10k \
  --resume-from checkpoints/best_model.pth \
  --skip-stage1 \
  --stage2-batch-size 1 \
  --gradient-checkpointing \
  --progressive-unfreeze
```

## ğŸ“Š What Will Happen

```
1. Load checkpoint (epoch 30, IoU 0.5480)
2. Skip Stage 1 âœ“
3. Clean memory
4. Reduce batch size (2 â†’ 1)
5. Start Stage 2 with progressive unfreezing:

   Epochs 31-60:  Unfreeze last layer     â†’ Target IoU: 0.60
   Epochs 61-90:  Unfreeze last 2 layers  â†’ Target IoU: 0.65
   Epochs 91-120: Unfreeze all layers     â†’ Target IoU: 0.72+
```

## âš¡ Memory Optimizations Applied

| Optimization | Memory Saved | Applied |
|--------------|--------------|---------|
| Stage 2 batch size reduced (2â†’1) | ~30% | âœ… |
| Gradient checkpointing | ~25% | âœ… |
| Progressive unfreezing | ~40% (early) | âœ… |
| Memory cleanup between stages | ~1-2GB | âœ… |
| **Total GPU usage** | **~13 GB / 14.74 GB** | âœ… Safe! |

## ğŸ” Verify It's Working

You should see this output:

```
======================================================================
LOADING CHECKPOINT: checkpoints/best_model.pth
======================================================================
âœ“ Loaded checkpoint from epoch 29
âœ“ Best IoU so far: 0.5480
âœ“ Resuming from epoch 30

â© Skipping Stage 1 (resuming from epoch 30)

ğŸ§¹ Cleaning up memory before Stage 2...
GPU Memory: XX.XX GB allocated | XX.XX GB reserved

======================================================================
STAGE 2: FULL FINE-TUNING
======================================================================
ğŸ”§ Reducing batch size: 2 â†’ 1
ğŸ“ˆ Using progressive unfreezing strategy
âœ“ Backbone: Last 1/4 layers unfrozen

Epoch 31/120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [07:30<00:00]
```

## ğŸ†˜ If You Still Get OOM

Try ultra-conservative settings:

```bash
python train_ultimate.py train \
  --dataset-path /kaggle/input/cod10k \
  --resume-from checkpoints/best_model.pth \
  --skip-stage1 \
  --stage2-batch-size 1 \
  --accumulation-steps 8 \
  --gradient-checkpointing \
  --progressive-unfreeze \
  --img-size 352
```

This uses:
- Smaller images (352 instead of 384): -15% memory
- More gradient accumulation (8 instead of 4): maintains effective batch size
- All optimizations enabled

## ğŸ“š Full Documentation

- **Complete guide**: See `KAGGLE_RESUME_GUIDE.md`
- **Memory analysis**: See `GPU_BOTTLENECK_ANALYSIS.md`
- **Memory profiling**: Run `python memory_profiler.py --find-optimal`

## ğŸ“ Understanding the Fix

**Why Stage 1 worked but Stage 2 failed:**

| Stage | Backbone | Gradients | Memory |
|-------|----------|-----------|--------|
| Stage 1 | Frozen â„ï¸ | Decoder only | ~8 GB âœ… |
| Stage 2 | Trainable ğŸ”¥ | Full model | ~17 GB âŒ |

**How we fixed it:**

1. **Reduced batch size**: 17 GB â†’ 13 GB âœ…
2. **Gradient checkpointing**: 13 GB â†’ 10 GB (with compute tradeoff)
3. **Progressive unfreezing**: Start at 8 GB, gradually increase

## â±ï¸ Training Time Estimate

- **Stage 2**: 90 epochs remaining
- **Time per epoch**: ~7-8 minutes (with batch_size=1)
- **Total time**: ~10-12 hours
- **Kaggle limit**: 12 hours per session âœ… Should fit!

**Tip**: Save checkpoints periodically in case session times out:
```python
!cp checkpoints/best_model.pth /kaggle/working/backup_epoch60.pth
```

## ğŸ¯ Expected Final Results

Based on Stage 1 performance (IoU: 0.5480), Stage 2 should achieve:

- **Conservative estimate**: IoU 0.68-0.70
- **Expected**: IoU 0.70-0.72 âœ… **SOTA target**
- **Optimistic**: IoU 0.72-0.74

You're well-positioned to hit the 0.72 target! ğŸ‰

---

**Ready to continue?** Run one of the three options above and watch your model improve! ğŸš€
